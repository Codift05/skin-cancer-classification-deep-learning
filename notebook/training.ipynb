{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c0fd6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c45d5b",
   "metadata": {},
   "source": [
    "\n",
    "classification of skin cancer images (Benign vs Malignant) using transfer learning with MobileNetV2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70100f",
   "metadata": {},
   "source": [
    "## Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "data_dir = Path(\"../data\")\n",
    "\n",
    "# Load dataset using image_dataset_from_directory\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42\n",
    "\n",
    "# Load all data\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=None  # None to get full dataset first\n",
    ")\n",
    "\n",
    "# Split into train and validation\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training batches: {len(train_dataset)}\")\n",
    "print(f\"Validation batches: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee809c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from dataset\n",
    "plt.figure(figsize=(12, 8))\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(min(9, len(images))):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label_idx = labels[i].numpy()\n",
    "        label_name = class_names[int(label_idx)]\n",
    "        plt.title(f\"Label: {label_name}\")\n",
    "        plt.axis(\"off\")\n",
    "plt.suptitle(\"Sample Images from Dataset\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Count images per class\n",
    "print(\"\\nDataset Statistics:\")\n",
    "benign_count = len([f for f in (data_dir / \"benign\").glob(\"*.*\")])\n",
    "malignant_count = len([f for f in (data_dir / \"malignant\").glob(\"*.*\")])\n",
    "print(f\"Benign images: {benign_count}\")\n",
    "print(f\"Malignant images: {malignant_count}\")\n",
    "print(f\"Total images: {benign_count + malignant_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f90f9",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd64077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values and create augmentation pipeline\n",
    "def normalize(image, label):\n",
    "    \"\"\"Normalize pixel values to 0-1 range\"\"\"\n",
    "    return image / 255.0, label\n",
    "\n",
    "# Apply normalization to datasets\n",
    "train_dataset = train_dataset.map(normalize).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(normalize).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Create data augmentation pipeline\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomBrightness(0.2),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "# Apply augmentation to training data\n",
    "train_dataset_augmented = train_dataset.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y),\n",
    "    num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Data augmentation pipeline created successfully!\")\n",
    "print(\"\\nAugmentation layers:\")\n",
    "print(\"- RandomFlip (horizontal)\")\n",
    "print(\"- RandomRotation (0.2)\")\n",
    "print(\"- RandomZoom (0.2)\")\n",
    "print(\"- RandomBrightness (0.2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmented images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for images, labels in train_dataset_augmented.take(1):\n",
    "    for i in range(min(9, len(images))):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy())\n",
    "        label_idx = labels[i].numpy()\n",
    "        label_name = class_names[int(label_idx)]\n",
    "        plt.title(f\"Augmented: {label_name}\")\n",
    "        plt.axis(\"off\")\n",
    "plt.suptitle(\"Sample Augmented Images\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2912da",
   "metadata": {},
   "source": [
    "## Build Transfer Learning Model with MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2587047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained MobileNetV2 model\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "# Freeze base model weights\n",
    "base_model.trainable = False\n",
    "\n",
    "print(f\"Base model loaded: MobileNetV2\")\n",
    "print(f\"Base model parameters: {base_model.count_params():,}\")\n",
    "\n",
    "# Build classification head\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu', name='dense_1'),\n",
    "    layers.Dropout(0.3, name='dropout_1'),\n",
    "    layers.Dense(1, activation='sigmoid', name='output')\n",
    "], name='skin_cancer_classifier')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Architecture Summary\")\n",
    "print(\"=\"*50)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f22a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy', \n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')]\n",
    ")\n",
    "\n",
    "print(\"\\nModel compiled successfully!\")\n",
    "print(f\"Loss: binary_crossentropy\")\n",
    "print(f\"Optimizer: Adam (lr=1e-4)\")\n",
    "print(f\"Metrics: Accuracy, Precision, Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91cc184",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ae37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Callbacks configured:\")\n",
    "print(\"- EarlyStopping (patience=5, monitor=val_loss)\")\n",
    "print(\"- ReduceLROnPlateau (factor=0.5, patience=3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ae1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "EPOCHS = 25\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset_augmented,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877fc5c",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_pred_prob = []\n",
    "\n",
    "for images, labels in val_dataset:\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred_prob.extend(predictions.flatten())\n",
    "    y_pred.extend((predictions > 0.5).astype(int).flatten())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_prob = np.array(y_pred_prob)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix - Validation Set', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ae1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Training vs Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training and validation curves displayed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12aaa64",
   "metadata": {},
   "source": [
    "## Save Model and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba996df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_save_path = Path(\"../model/model.h5\")\n",
    "model_save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model.save(model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "\n",
    "# Save labels\n",
    "labels_save_path = Path(\"../model/labels.txt\")\n",
    "with open(labels_save_path, 'w') as f:\n",
    "    for label in class_names:\n",
    "        f.write(f\"{label}\\n\")\n",
    "print(f\"Labels saved to: {labels_save_path}\")\n",
    "\n",
    "print(\"\\nModel and labels saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d000dbb",
   "metadata": {},
   "source": [
    "## Generate Grad-CAM Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6030fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM Implementation\n",
    "def generate_gradcam(model, img_array, layer_name):\n",
    "    \"\"\"\n",
    "    Generate Grad-CAM heatmap for model prediction visualization\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        img_array: Input image array (normalized, shape: (224, 224, 3))\n",
    "        layer_name: Name of convolutional layer for visualization\n",
    "    \n",
    "    Returns:\n",
    "        heatmap: Grad-CAM heatmap (224, 224)\n",
    "    \"\"\"\n",
    "    # Create a model that outputs both predictions and layer activations\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Record operations for automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(np.expand_dims(img_array, axis=0))\n",
    "        loss = predictions[:, 0]\n",
    "    \n",
    "    # Compute gradients\n",
    "    output = conv_outputs[0]\n",
    "    grads = tape.gradient(loss, conv_outputs)[0]\n",
    "    \n",
    "    # Compute weights (average pooling of gradients)\n",
    "    weights = tf.reduce_mean(grads, axis=(0, 1))\n",
    "    \n",
    "    # Generate heatmap\n",
    "    heatmap = tf.reduce_sum(tf.multiply(weights, output), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0)  # ReLU\n",
    "    heatmap /= tf.math.reduce_max(heatmap)  # Normalize to 0-1\n",
    "    \n",
    "    return heatmap.numpy()\n",
    "\n",
    "def overlay_gradcam(img_array, heatmap, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Overlay Grad-CAM heatmap on original image\n",
    "    \n",
    "    Args:\n",
    "        img_array: Original image (224, 224, 3)\n",
    "        heatmap: Grad-CAM heatmap (224, 224)\n",
    "        alpha: Transparency of heatmap overlay\n",
    "    \n",
    "    Returns:\n",
    "        overlaid_img: Image with overlaid heatmap\n",
    "    \"\"\"\n",
    "    # Resize heatmap to match image size\n",
    "    heatmap_resized = cv2.resize(heatmap, (224, 224))\n",
    "    \n",
    "    # Create color heatmap (red for high activation)\n",
    "    heatmap_colored = cv2.applyColorMap(\n",
    "        (heatmap_resized * 255).astype(np.uint8),\n",
    "        cv2.COLORMAP_JET\n",
    "    )\n",
    "    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Overlay on image\n",
    "    img_for_overlay = (img_array * 255).astype(np.uint8)\n",
    "    overlaid = cv2.addWeighted(img_for_overlay, 1 - alpha, heatmap_colored, alpha, 0)\n",
    "    \n",
    "    return overlaid\n",
    "\n",
    "print(\"Grad-CAM functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b1b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Grad-CAM example visualization\n",
    "# Get a sample image from validation set\n",
    "sample_images, sample_labels = next(iter(val_dataset.take(1)))\n",
    "sample_img = sample_images[0].numpy()\n",
    "sample_label = sample_labels[0].numpy()\n",
    "\n",
    "# Generate Grad-CAM\n",
    "layer_name = 'mobilenetv2_1_out_relu'  # Last layer before classification head\n",
    "heatmap = generate_gradcam(model, sample_img, layer_name)\n",
    "overlaid_img = overlay_gradcam(sample_img, heatmap, alpha=0.4)\n",
    "\n",
    "# Get prediction\n",
    "prediction = model.predict(np.expand_dims(sample_img, axis=0), verbose=0)[0][0]\n",
    "pred_class = class_names[int(prediction > 0.5)]\n",
    "pred_confidence = (prediction * 100) if prediction > 0.5 else ((1 - prediction) * 100)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(sample_img)\n",
    "axes[0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Heatmap\n",
    "axes[1].imshow(heatmap, cmap='jet')\n",
    "axes[1].set_title('Grad-CAM Heatmap', fontsize=12, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Overlaid image\n",
    "axes[2].imshow(overlaid_img)\n",
    "axes[2].set_title(f'Overlaid (Pred: {pred_class} - {pred_confidence:.2f}%)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "gradcam_path = Path(\"../model/gradcam_example.png\")\n",
    "plt.savefig(gradcam_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"Grad-CAM example saved to: {gradcam_path}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
